\section{Monitoring Approach}
\label{sec:approach}

Our optimized monitoring approach strives to reduce the memory requirements
of finite state monitoring and make it efficient. At the same time it also tries to make monitoring more 
time-deterministic without compromising too much with its error reporting. The following subsections
give an overview of the approach, and describe the monitoring algorithm as well as its key features.

%The approach is based on the following mechanisms.

%Section~\ref{subsec:outline} gives the outline of our approach, and
%Section~\ref{subsec:algo} presents the algorithm.

\subsection{Outline of the approach}
\label{subsec:outline}

\begin{figure}[t]
\centering
  \includegraphics[width=\linewidth]{./images/optimized_monitoring_scheme.pdf}
  \caption[Schematic of Memory-efficient and Time-Deterministic Monitoring 
System]{Schematic of Memory-efficient and Time-Deterministic Monitoring System.}
  \label{fig:schematic}
\end{figure}

Figure~\ref{fig:schematic} shows the main elements of our approach. The program 
under execution generates events parameterized by objects which are accepted by 
our monitoring system, and each one of them is handed over to the monitor 
allocation module. This module contains information about the symbol types, the current execution context, 
the history of the observed execution contexts, and the global monitor pool.
Based on the type of the symbol, which is part of the event, and some heuristics 
based on the program execution context, the allocation module makes a decision about whether to allocate a monitor or not.
For convenience, if not already available, we 
specify explicitly the program points that generate creation events, so that the 
approach can leverage this information to make a decision about monitor allocation and tracking. 
If the event is of creation type, the allocation module checks the execution context and its 
tracking history to see if the context was already seen in the past, and if yes, 
then with what frequency. The system probabilistically skips the monitor 
allocation phase for frequently seen contexts. The contexts can generally be maintained as
trees in which case a new context either adds a new branch or new branches and a leaf node. 
Every leaf node uniquely defines a context and it keeps information about the 
number of times the context was seen. Currently, the seen contexts are stored as bitmaps to enable efficient
comparisons, and this mechanism can be improved further for efficiency.

The global monitor pool is implemented as a circular array that preserves 
the chronological ordering. In case the allocation module chooses to allocate a monitor,
it picks the next available monitor for allocation. The monitor being allocated could be already in use.
In this case the monitor is first removed from the existing local pools of the associated 
objects, and then reallocated to the new objects under consideration. This allocation results in the monitor
getting added to the local pools that belong to the associated objects. The local pools also have a limit of their mximum size.
In case, any of the concerned local pool is already full, the oldest monitor from the pool is removed and returned to the global pool
to create room for the new monitor. 

The tracking of monitors for the non-creation events is similar to the 
conventional monitoring system. The only difference is that if no monitor exists in the maps 
corresponding to the objects associated with the incurred event, then monitoring is completely 
skipped for that event. This case can only happen when the monitors corresponding to the 
associated objects were intentionally not created by the system. Skipping monitoring events is a 
direct saving in terms of execution time overhead. In case any of the monitors goes to the error state,
an error report is generated.


\subsection{Context-based sampling}

We use context-based sampling of objects to control the 
number of monitors. The motivation for this approach comes from our observation 
that monitors created at the same creation site and under similar program
execution context tend to go through a similar life cycle. In other words, these monitors are more 
likely to show a redundant behavior. Hence, the heuristic applied for this 
sampling is based on the program execution context. Our approach works by i) identifying 
the monitor creation sites which are specified as creation events in the 
monitoring specification, and then by ii) obtaining the method calling sequence to identify 
the execution context, and finally by iii) making a decision about the 
allocation of the monitor based on the number of times this context was seen in 
the past. More often the monitoring system has seen the context, less likely it 
is to allocate a monitor. The program execution context that we consider in this work is
the method calling sequence of limited length. We describe the implementation details
in Section~\ref{sec:implementation}.

\subsection{Fixed-size global pool of monitors}

We limit the total number of monitors that our monitoring approach might generate by creating a 
monitor-pool of fixed size prior to the program execution and then maintaining 
it during the execution. In short our approach reuse monitors. The monitors 
after their usage can be returned back to the system. Moreover, if the pool runs 
out of monitors and the system needs a new monitor, one of the monitors currently being 
used is forcefully reclaimed and made available for the reallocation. The 
heuristic that we use to reclaim a monitor is based on our observations that the 
program events related to the same objects are often temporally separated from the rest,
and events are more likely to be generated by newly created objects. In other words, in an execution 
trace, events related to the same or related objects often occur together.
We exploit this observation by making the oldest
monitor available for reallocation. This also means that the objects associated with that monitor
are not tracked further, and if they had observed a sequence of events that might have otherwise
lead the monitor to the error state, the approach will now miss the error. 
Potentially missing a few errors is a cost of our optimized monitoring approach.
However, by using the heuristics presented in this Section the approach tries to
minimize \textit{false negatives}. As described in Section~\ref{sec:definition}, our
goal is to detect all non-redundant errors, and not all errors.

\subsection{Fixed-size local pool of monitors for indexed objects}

In the case of properties related to multiple objects, 
an object can get associated with numerous monitors in its life-time. For example,
in the case of \texttt{UnsafeIterator} property a collection object may get associated
with numerous iterator objects in its life-time. In other words, every pair of a collection and its related
iterator has an associated monitor. Hence, a collection may have several monitors associated with it
and they are stored in a map corresponding to the collection object as a key.
Therefore, an event related to the collection object results in the states of 
several monitors getting updated. Hence, handling such events may become 
\textit{nondeterministic} in terms of their execution times even when the events are related
to a same symbol, or to a same set of objects but at different times.

For this work, we consider a monitoring behavior to be time-deterministic if we 
can compute the 
worst-case time taken to execute every monitoring event. Binding the number of 
monitors associated with an object allows us to limit the worst case execution 
time for any monitoring operation associated with that object. Our approach 
implements this constraint by allocating a fixed-size local pool of monitors to 
individual objects. We reallocate an existing monitor in case this buffer is full and we need a new
monitor for the same set of objects.



\begin{algorithm}[t]
                      % enter the algorithm environment
\caption[Algorithm]{Context-Aware Monitoring. Input: $\phi$ = 
($Q$,$\Sigma$,$\delta$,$q_{0}$,$F$, err), $\eta=(\beta, \sigma)$ where $\eta$ is an event and $\beta \in 2^O$ 
be the set of associated objects and $\sigma \in \Sigma$}          % give the algorithm 
% a caption
\label{alg1}                           % and a label for \ref{} commands later 
% in the document
\begin{algorithmic}[1]                  
   \STATE \textbf{let} $\Sigma_{c} \in \Sigma$ be the set of creation symbols
   \STATE \textbf{let} \textit{A} be the global circular array of monitors
    \STATE \textbf{let} $\psi$ : $2^O \nrightarrow 2^M$ be a mapping that returns the monitors associated with a given set of objects.
   \STATE \textbf{let} $\tau$ : $M \nrightarrow 2^O$ be a mapping that returns the objects associated with a monitor
   \STATE \textbf{let} $\pi \in \Pi$ be a finite sequence of method structures
   \STATE \textbf{let} $\zeta$ be the data structure holding program execution contexts
  
   
    \IF{$\sigma \in \Sigma_{c}$}
        \STATE $\pi$  $\leftarrow$ getExecutionContextInfo()
        \IF{isPresent($\pi$, $\zeta$) = TRUE}
           \STATE $k$ $\leftarrow$ threshold($\pi$, $\zeta$)
        \ELSE
        	   \STATE $k \leftarrow 1$
        \ENDIF
        \STATE updateExecutionContext($\pi$, $\zeta$)
        \IF{Random() $\leq k$}  
            	\STATE $m$ $\leftarrow$ $A$.nextMonitor()
        		\FORALL {$\alpha' \subseteq$ $\tau$($m$)} 
		\STATE $\psi$($\alpha'$) $\leftarrow  \psi(\alpha') / \{m\}$
        		\ENDFOR
        		\FORALL {$\alpha' \subseteq \beta $} 
			\IF{$\psi$($\alpha'$).size() = \textit{max\_mon}}
				 \STATE $m' \leftarrow$ $\psi$($\alpha'$).first();
			  	\FORALL{$\alpha'' \subseteq$ $\tau$($m'$)} 
					\STATE $\psi$($\alpha''$) $\leftarrow$  
$\psi$($\alpha''$) / \{$m'$\}
        				\ENDFOR
			\ENDIF
                		 \STATE $\psi$($\alpha'$) $\leftarrow$  
$\psi$($\alpha'$) $\cup$ \{$m$\}
        		\ENDFOR
        \ENDIF
 \ENDIF
 \FORALL{$m$ $\in$ $\psi$($\beta$)}
     \STATE $m$.cur $\leftarrow$ $\delta$($m$.cur,$\sigma$)
     \IF{$m$.cur = err}
        \STATE report$\hspace{5pt}\textbf{error}$
     \ENDIF
 \ENDFOR
 
\end{algorithmic}

\end{algorithm}
\label{algo:monitoring}



\section{Monitoring Algorithm}
\label{sec:algo}

Algorithm~1 depicts the steps that implement our monitoring scheme. It takes a
property $\phi$ and an event $\eta$ as input. Lines 7--30 
describe the operations that are performed when a creation event is encountered 
and a new monitor may need to be allocated. Line 8 reads the program execution 
context. If the execution context is already seen which is checked at line 9, 
then a \textit{threshold} value is generated based on the number of times the 
context is seen in the past; else if the context is unseen, the threshold is 
assigned the highest possible value which is 1. In either case line 14 updates 
the execution context history.
%In our implementation it involves either adding 
%new branches in the context tree if the context was unseen or only incrementing 
%the frequency count filed of the leaf node corresponding to the known context.

Lines 15--29 describe the steps when the threshold value is found to be large 
enough to justify allocation of a monitor which is checked by the condition at 
line 15. As a result, a new monitor from the global circular array is allocated
at line 16. Lines 17--19 describe the steps to reclaim the monitor in case it is previously 
assigned. This step ensures that all previous bindings are removed and the 
monitor is ready for the new assignment.

Lines 20--28 describe the steps that ensure that the local monitor pool limit is 
not reached. In case it is, the oldest monitor in the pool is reclaimed first by 
removing it from all the lists of associated objects' maps before the new monitor 
is added in the lists as shown by line 27.

Finally, as shown in lines 31--36, the relevant monitors are retrieved and their 
states are updated. In case any of the state is the \textit{error} state, then 
the error is reported. This final step is similar to the conventional 
monitoring, except that no monitor will be tracked if the system does not see 
any monitor allocated.

\subsection{Correctness}
\label{subsec:correctness}

We define correctness of our algorithm by arguing about its \textit{soundness} and \textit{completeness}
with respect to the general unoptimized approach. The major difference between 
the two approaches is in the way the monitors are generated. The unoptimized approach
creates new monitors after every creation event, whereas we either allocate them
from the pool or skip the allocation completely. The allocation can be further divided
into two cases: a) In the case when we allocate a fresh monitor from the pool, there is no
difference in the way the newly allocated monitor is tracked in the two approaches, and the
correctness argument should automatically hold. b) In the case when
we reuse a monitor, we first remove all of the current bindings by removing
the monitor from all of the local pools. This ensures that there is no undesirable side-effect
and the newly allocated monitor tracks the only events that are related to the new set of
objects. As a result \textit{false positives} are never produced and the completeness is
never compromised. Similarly for completely skipped monitors false error reports are 
never reported for obvious reasons.

Runtime monitoring is inherently 
unsound \cite{}. It can report only based on what it has observed. This means errors 
may not be reported if the paths that encounter them are not exercised. In both of the allocation cases
discussed above, if the newly allocated monitor gets reallocated in the future before it can report
any error, we may lose the system's soundness further with respect to the unoptimized approach. The same argument 
applies to the skip case. Note that all monitors apart from the one that gets reallocated continue
their functioning in a way similar to the unoptimized monitoring, and report errors as and when they detect any.

\subsection{Memory and Time Efficiency }
\label{subsec:memory efficiency}

The algorithm preallocates monitors from a pool of constant size, and then if 
required, monitors are reused. In our study we varied the pool size from 1k 
to 30k monitors. This results in the reduction of the number of required monitors 
considerably especially for challenging program and property combinations in 
which a very large number of monitors may get generated. In fact, as the study indicates,
for some configurations the system ended up consuming
even less monitors than the size of the global monitor pool due to
limited program execution contexts that were
observed during runtime. This shows that an approach based on the execution
contexts may result in a dramatic saving in the memory requirements of a
software application.

The reduced number of monitors allow us to skip monitoring actions. Even though
maintaining and checking execution contexts as well as reclaiming monitors add to the overhead, 
a simple memory management that involves easy monitor allocation from fixed-size pools helps maintain the
system's efficiency. In addition, it reduces the system's dependence on the garbage collector since no
monitors need to be cleaned. Apart from saving execution time it also reduces the unpredictability
of the execution time introduced by the garbage collector.

\subsection{Time-Determinism}
\label{subsec:timedeterminism}

It is easy to see that the algorithm has fairly tight worst-case execution time bounds
for all of its steps making it time-deterministic. This can be explained
by analysing the bounds on the steps involved in handling a monitoring event.
We divide the event-handling analysis into the following two categories.

\paragraph{Handling of creation events} A creation event may result in a monitor
allocation depending on the program execution context under which it was generated.
Accessing the context on line 8 is a constant time operation. Method \code{isPresent} on
line 9 traverses entire depth of the context tree in the worst case, which makes it
constant time since the tree has a limited height. Updating the execution context on line 14
cannot take longer than the time required to traverse the depth of the tree for the same reason.
The loop on lines 17--19 iterates $2^n$ times and hence takes $O(2^n)$ time 
where $n$ is $\mid\tau(m)\mid$ and $\tau(m)$ is the number of associated objects 
and is normally less than four. Hence, this operation takes $\Theta(1)$ time. By the same arguments
loops on lines 23--25 and 20--28 iterate $2^{\mid\tau(m)\mid}$ and $2^\beta$ times and take $\Theta(1)$
time since these numbers are small and often less than four. Hence, the worst case running time
of the outer loop on lines 20--28 is $\Theta(1)$. Therefore the time taken by a creation event in the
worst case is constant.

\paragraph{Handling of other events}
Since the size of the local monitor pools is limited to a small number, the loop on lines 31--36
executes at most $k$ times where $k$ the size of the local monitor pool. For properties, that are
associated with only one object this number is one. Hence, the handling of other events takes a
constant time irrespective of the objects associated with the property.

Hence, we see that the algorithm has worst case execution time of
$\Theta$(1). For a program execution that  generates $n$ events, the time taken to handle 
these events by our approach in the worst case is $O(n)$. In comparison, in the worst case,
the unoptimized algorithm may create $O(n)$ monitors, assign all of them to a set of objects,
 and then receive events of similar kind on the same set of objects
 requiring all of the created monitors to be tracked for every event. Therefore, the worst-case complexity of the
 unoptimized algorithm where $n$ is the number of events would be $O(n^2)$. Even though we expect this worst case to arise 
 in the practice rarely, we expect our algorithm to work faster than the unoptimized algorithm in the practice.
 
\subsection{Soundness, Memory, Efficiency, and Time-Determinism: Tradeoffs}
\label{subsec:tradeoff}

There is unfortunately a tradeoff between soundness of the system and the
number of monitors allocated, which in turn, corresponds to the memory allocated
for monitoring, and we pick one at a potential loss of the other.
%However, runtime monitoring is inherently 
%unsound \cite{}. It can report only based on what it has observed. This means errors 
%may not be reported if the paths that encounter them are not exercised.
We stretch the inherent unsoundness of any monitoring system a little bit further to achieve substantial benefits in 
terms of memory savings, and at the same time use heuristics that help maintain
the system's soundness.  As a result, our technique should enable developers to employ runtime 
monitoring in resource-constrained system settings where the previous 
techniques for finite-state monitoring might not have been feasible.

Similar tradeoffs exist between soundness and efficiency, and soundness and time-determinism.
However, binding worst-case execution times has its own merits 
especially in the domain of real-time systems or with systems requiring high performance.
Hence, our approach uses effective heuristics based on our observations and experience so as to reduce false 
negatives and improve the soundness of the system. As indicated by the study
in Section~\ref{sec:evaluation}, the approach can save considerable amount of
memory, improve its efficiency, and can also make monitoring time-deterministic.

Since, the monitors that produce errors are continuously tracked from the beginning similar to the
conventional unoptimized approach, the optimized approach does not 
compromise with its \textit{completeness} , and ensures that no false positives 
are ever produced.


\ignore{
\subsection{Memory-Efficiency and Time-Determinism}
\label{subsec:efficiencyanddeterminism}

The algorithm preallocates monitors from a pool of constant size, and then if 
required, the monitors are reused. In our study we varied the pool size from 1k 
to 30k monitors. This results in reducing the number of required monitors 
considerably especially for challenging program and property combinations in 
which a very large number of monitors get generated. As our study indicates, our approach 
may result in a dramatic saving in the memory requirements of a software.

It is easy to see that the algorithm has worst-case time bounds for all of its 
steps making the algorithm time-deterministic. Fetching current execution 
context in the form of a call stack is an expensive but still a constant time 
operation. The execution context tree has a bounded depth which we have limited 
to four in our prototype implementation. Hence performing read or write 
operations on it as in lines 11 and 16 are time-bound operations.

Depending on the map implementations, all the map operations such as the ones on 
lines 20, 26, and 29 are constant-time operations. The \textit{for} loops on 
lines 19, 22 and 25 iterate only a small finite number of times depending on the 
number of objects involved in the event which is typically either one or two. 
The \textit{for} loop on line 33 executes at most \texttt{MAX\_MON} times since 
that is the limit on the size of local monitor pools associated with objects.

We show in Section~\ref{subsec:tradeoff} that the algorithm has worst case bound of
$\Theta$(1). In which case the worst-case complexity of this algorithm is $O(n)$
where $n$ is the number events encountered. In comparison, in the worst case,
the unoptimized algorithm may create $O(n)$ monitors, assign all of them to a set of objects,
 and then receive events of similar kind on the same set objects
 requiring all of the created monitors to be tracked together.  The complexity of the
 unoptimized algorithm then would be quadratic. Even though we expect the worst case to arise 
 in the practice rarely, we expect our algorithm to work faster than the unoptimized one in the practice.
 }








\ignore{
\section{Simple Code and Property Example:}
While JavaMOP represents state of art runtime monitoring, our goal is to limit 
the number of monitors associated with a set of objects. It typically models 
sequencing properties as finite state automata (FSA) and check whether a program 
satisfies them during runtime.  JavaMOP uses object based monitoring in which a 
monitor for a FSA property is a relation between a set of related objects 
created during program execution and a state of the FSA.  The execution of 
sequence of program statements (under test), related to both property and the 
set of related objects, corresponds to the sequence of FSA transitions.\\
\begin{figure}[h]
\centering
  \includegraphics[scale=0.6]{./images/Unsafe.jpg}
  \caption[UnsafeIterator Property FSA]{UnSafeIterator Property.}
  \label{fig:typestateProperty FSA}
\end{figure}
\\Let us assume we are monitoring UnsafeIterator property that says not to 
modify an object of class Collection while iterating over this collection at the 
same time. In this case, it would be unclear whether the program should iterate 
over the original contents or the modified contents of the collection. While 
iterating over a collection, the runtime monitoring ensures that the program 
behaviour is well-defined. In other words, the monitor checks that there should 
not be a call to any method that is updating the collection after an iterator is 
created and before an element is accessed by a call to method next. The regular 
expression for the property is (create ; next* ; update*) and Fig 3.1 shows the 
finite state automata for UnsafeIterator property.\\\\
Below shows a code snippet for a test program. The relevant statements for the 
above property are calls to methods iterator(), add(), and next() on appropriate 
receiver objects. The relevant statements in the fragment of code being 
monitored are instrumented with extra code i.e., the OBSERVE... calls to perform 
monitoring.\\\\
When the call to method iterator() is encountered, a monitoring event create is 
generated. The instrumented code maintains a map, keyed by set of related 
objects that have been involved in previous events. The values corresponding to 
the keys are the set of monitors that are associated with the objects. On 
handling the create event, if it is found that no monitors are associated with 
the collection \textit{m1} and iterator \textit{itr}, our approach will list the 
history of method calls on the object \textit{itr} (bar(a1,a2), third(a1,a2), 
second(a1,a2), first(a1,a2), main() from our example). It will analyse if there 
exists same method calls of previously monitored objects and will sample the 
object for monitoring if match is not found and it will store the history of 
method calls for this object. However, on finding a match, the object may or may 
not be considered for monitoring depending upon how frequently it has been 
monitored previously.
\begin{center}
\textbf{A code snippet}
\begin{lstlisting}

void main(String[] args) {
	  ArrayList a1 = new ArrayList();
     al.add("C");
	  al.add("A");
	  al.add("B"); 
	  ArrayList a2 = new ArrayList ();
	  first(a1,a2);
	}
void first(ArrayList a1, ArrayList a2) { 
	  second(a1,a2); 
	} 
void second(ArrayList a1, ArrayList a2) {
	  third(a1,a2); 
	} 
void third(ArrayList a1, ArrayList a2) {
	  bar(a1,a2); 
	}
void bar(ArrayList m1,Arraylist m2) {
	  Iterator itr = m1.iterator();
		   OBSERVE.create(m1,itr);
	  m2.add(?ÄúX?Äù);
		   OBSERVE.update(m2);
     while(itr.hasNext()) {
	    Object element = itr.next();
		   OBSERVE.next(itr);
	  }
	}
    
\end{lstlisting}
\end{center}


Whenever an object is sampled for monitoring, the total number of monitors 
analysing the property are checked. If the number is below the specified limit, 
a new monitor is created and references to it are associated with the new keys 
\textit{m1} and \textit{itr} and on the other hand, if the number exceeds the 
limit, the previously generated monitor is reassigned for the current objects by 
changing the references. Thus, a limited set of monitors is used for analysing 
the property violations as done in runtime monitoring. 
}














\ignore{
\begin{algorithm}[h]
                      % enter the algorithm environment
\caption[Algorithm]{Monitoring Algorithm. $\phi$ = 
(Q,$\Sigma$,$\delta$,$q_{0}$,F), e=(l,b) where e is an event and l $\in \Sigma$ 
and b $\in O$ be the set of receiver objects}          % give the algorithm a 
caption
\label{alg1}                           % and a label for \ref{} commands later 
in the document
\begin{algorithmic}[1]                  
   %\STATE \textbf{let} \textit{O} be the set objects that receive events
   \STATE \textbf{let} $\Sigma_{c} \in \Sigma$ be the set of creation symbols
   \STATE \textbf{let} \textit{prob} determines the generation of monitor 
(Initializing it to 1).
   \STATE \textbf{let} \textit{MA} be the array of monitors
   \STATE \textbf{let} \textit{ObjMonsMap} : \textit{O} $\to$ \textit{MS} be a 
map
   \STATE \textbf{let} \textit{ObjsSym} be a binary relation over L and $\Sigma$
   \STATE \textbf{let} \textit{SE} be a finite sequence of method frames
   
    \IF{$b \in \Sigma_{c}  \lor \textit{ObjMonsMap(o)} = null$}
        \STATE $SE  \leftarrow retrieveMethodCalls(o)$
        \FOR{$SE' \subseteq SE$} 
           \STATE $match  \leftarrow
           isMatched(SE')$
        \ENDFOR
        \IF{$(match)$}
           \STATE $prob \leftarrow P(countOfMatches)$
        \ENDIF   
        \IF{$ ((\exists(rand)\subset RNG : rand < prob))$}  
            \IF{$sizeOf (MA) < limit$} 
                \STATE $ m \leftarrow new monitor(o),MA \leftarrow m $
            \ELSE
                \STATE $m \leftarrow retrieve(MA[index]) $
            \ENDIF   
            \STATE $monitoringFlag \leftarrow  true$    
        \ELSE
            \STATE $monitoringFlag \leftarrow  false$ 
        \ENDIF
        \FOR{$l' \subseteq l $} 
            \IF{$\exists \sigma \in \Sigma : (l', \sigma) \in ObjsSym $}
                \IF{$(monitoringFlag) $} 
                   \STATE $ObjsMons(l') \leftarrow  ObjsMons(l') \cup \{m\}$
                \ENDIF
            \ENDIF   
        \ENDFOR
 \ENDIF
 \FOR{$m \in MA$}
     \STATE $m.cur \leftarrow \delta(m.cur,b)$
     \IF{$(m.cur = err)$}
        \STATE report$\hspace{5pt}\textbf{error}$
     \ENDIF
 \ENDFOR
\end{algorithmic}

\end{algorithm}
}

\ignore{Runtime Monitoring is complete but fundamentally unsound since it cannot 
see anything beyond the current execution. In our approach, we sacrifice on the 
soundness to achieve memory efficiency and determinism in terms of time.	

The aim of our research is to develop optimization techniques without 
compromising heavily with the error reporting. We have developed techniques that 
identify objects in a program for which new monitors will be generated only if 
they satisfy the required probability related to the program execution context. 
We are guided by the heuristics that considers the history of method calls that 
have been invoked on the current object being monitored over the course of 
object?Äôs lifetime, from allocation to collection, as the decision factor to 
determine if the object has been previously monitored.\\\\ 
In object based monitoring, for every object that invokes a property for 
monitoring, an instance of monitor is created and all subsequent calls on those 
objects generate events[14]. It may be the case that an object A following a 
particular sequence of method calls, reaches a method where the typestate 
property of the current object is monitored for violation and there is another 
object B which follows the same method call trace as A and reaches the same 
method. Here, the conventional monitoring approach will create again a new 
monitor for the second method invocation to check for property violation 
although the objects of this method have been previously monitored. Thus, in our 
approach, we are sampling the objects that are to be monitored. The new monitor 
instances are generated for sampled objects and the objects are sampled by 
listing the history of method calls invoked on the objects.\\
Our approach is built on dynamic typestate analysis and limits the number of 
monitors that are associated with events related to a set of objects. Moreover, 
the total number of monitors generated for the typestate property checking is 
bounded explicitly in our work. A monitor pool is maintained and once the number 
of monitors generated reaches the limit specified, the already generated 
monitors are reassigned for checking the violation of the properties. This helps 
in utilizing the memory efficiently and reduces memory overhead.\\\\
For a multi-object property, those that involve more than one object such as 
\textit{UnSafeIterator} property, one \textit{Collection} object has several 
monitors associated with it at a time. This means that a single method call on 
that object can result in several monitor
update operations. The number of associated monitors can grow uncontrollably and 
it becomes difficult to keep a track of every monitor for that event, hence the 
whole operation of handling events may become non-deterministic in terms of 
execution time. By limiting the number of monitors associated, the events become 
bounded and  hence, our approach makes monitoring deterministic in terms of 
time. We provide worst-case bounds for the execution times of handling events.}
